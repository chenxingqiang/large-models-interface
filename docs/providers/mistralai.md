![Mistral AI](https://samestrin.github.io/media/large-models-interface/mistralai.png)

# [Mistral AI](https://mistral.ai)

Mistral AI is a French artificial intelligence company focused on developing and providing large language models (LLMs). They emphasize open-source principles, making their models accessible and customizable for various applications. Mistral AI offers a range of models with varying sizes and capabilities, catering to different user needs. The company has gained significant attention and funding due to its commitment to transparency and collaboration within the AI community.

## Interface Name

- `mistralai`

### Example Usage

```javascript
const { LLMInterface } = require('large-models-interface');

LLMInterface.setApiKey({'mistralai': process.env.MISTRALAI_API_KEY});

async function main() {
  try {
    const response = await LLMInterface.sendMessage('mistralai', 'Explain the importance of low latency LLMs.');
    console.log(response.results);
  } catch (error) {
    console.error(error);
    throw error;
  }
}

main();
```

### Model Aliases

The following model aliases are provided for this provider. 

- `default`: mistral-large-latest
- `large`: mistral-large-latest
- `small`: mistral-small-latest
- `agent`: mistral-large-latest

### Embeddings Model Aliases

- `default`: mistral-embed
- `large`: mistral-embed
- `small`: mistral-embed


## Options

The following parameters can be passed through `options`.

- `max_tokens`: The maximum number of tokens that can be generated in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length.
- `random_seed`: _Details not available, please refer to the LLM provider documentation._
- `response_format`: Defines the format of the AI's response. Setting this to { "type": "json_object" } enables JSON mode, ensuring the message generated by the model is valid JSON.
- `safe_prompt`: _Details not available, please refer to the LLM provider documentation._
- `stream`: If set, partial message deltas will be sent, similar to ChatGPT. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message.
- `temperature`: Controls the randomness of the AI's responses. A higher temperature results in more random outputs, while a lower temperature makes the output more focused and deterministic. Generally, it is recommended to alter this or top_p, but not both.
- `top_p`: Controls the cumulative probability of token selections for nucleus sampling. It limits the tokens to the smallest set whose cumulative probability exceeds the threshold. It is recommended to alter this or temperature, but not both.


### Features

- Native JSON Mode
- Streaming
- Embeddings


## Getting an API Key

**Commercial with Free Trial:** The MistralAI API is a commercial product but offers a $5.00 credit to get started. No credit card is required initially.

To get an API key, first create a Mistral AI account, then visit the link below.

- https://console.mistralai.ai/api-keys/


## [Mistral AI Documentation](https://docs.mistral.ai/)

[Mistral AI documentation](https://docs.mistral.ai/) is available [here](https://docs.mistral.ai/).
